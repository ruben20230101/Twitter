{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6599a86",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 0. Gathering the data\n",
    "\n",
    "* Gathering √\n",
    "* Assessing √\n",
    "* Cleaning √\n",
    "* Analyzing and visualizing √\n",
    "* Reporting √"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce75b556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries required for this notebook to run\n",
    "\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('max_colwidth', 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576a9307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload archive and read the data into a pandas DataFrame\n",
    "\n",
    "df_archive = pd.read_csv(\"twitter-archive-enhanced.csv\")\n",
    "df_archive.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262aeb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_archive.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb35905d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The HTTP 200 OK success status response code indicates that the request has succeeded \n",
    "\n",
    "url = \"https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv\"\n",
    "response = requests.get(url)\n",
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30f842f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"image_predictions.tsv\", mode='wb') as file:\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db11a1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_images_predictions = pd.read_csv(\"image_predictions.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc9c37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_images_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c054e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_images_predictions.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1321b7f2",
   "metadata": {},
   "source": [
    "# Executed and turned off (NOT the most recent version)\n",
    "\n",
    "!pip install -U tweepy==4.0"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0fb38f22",
   "metadata": {},
   "source": [
    "import tweepy\n",
    "# https://stackoverflow.com/questions/66156958/how-to-acess-tweets-with-bearer-token-using-tweepy-in-python\n",
    "\n",
    "consumer_key = \"[Deleted]\" # put here your API Key\n",
    "consumer_secret =\"[Deleted]\" # put here your API Key Secret\n",
    "auth = tweepy.AppAuthHandler(consumer_key, consumer_secret)\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a7e0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_ids = df_archive.tweet_id.values\n",
    "len(tweet_ids)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "411c0162",
   "metadata": {},
   "source": [
    "# I made this cell inactive after quering it, as was recommended by my instructor.\n",
    "# Therefor, tweet_json.txt is original\n",
    "\n",
    "%%time\n",
    "\n",
    "import json\n",
    "\n",
    "# Query Twitter's API for JSON data for each tweet ID in the Twitter archive\n",
    "count = 0\n",
    "fails_dict = {}\n",
    "# Save each tweet's returned JSON as a new line in a .txt file\n",
    "with open('tweet_json.txt', 'w') as outfile:\n",
    "    # This loop will likely take 20-30 minutes to run because of Twitter's rate limit\n",
    "    for tweet_id in tweet_ids:\n",
    "        count += 1\n",
    "        print(str(count) + \": \" + str(tweet_id))\n",
    "        try:\n",
    "            tweet = api.get_status(tweet_id, tweet_mode='extended')\n",
    "            json.dump(tweet._json, outfile)\n",
    "            print(\"Success\")\n",
    "            outfile.write('\\n')\n",
    "        except Exception as e:\n",
    "            print(\"Fail\")\n",
    "            fails_dict[tweet_id] = e\n",
    "        \n",
    "\n",
    "print(fails_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49861fcc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_json = pd.read_json(\"tweet_json.txt\", lines=True, encoding = 'utf-8')\n",
    "df_json.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb5a1a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_json = df_json[['id', 'favorite_count', 'retweet_count']]\n",
    "df_json.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d3e354",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f3bde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json.rename(columns={\"id\": \"tweet_id\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3dd9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 in merging\n",
    "\n",
    "df_1 = df_archive.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccec4052",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 2 in merging\n",
    "\n",
    "df_2 = df_1.merge(df_images_predictions, how='left', on='tweet_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5684a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 in merging \n",
    "\n",
    "df_3 = df_2.merge(df_json, how='left', on='tweet_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1747d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4, the copy of dataframe in which all three dataframes are combined\n",
    "\n",
    "df_all = df_3.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ce393a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 1. Assessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0e112a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99fee34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['tweet_id'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3002369d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772b3738",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4d7b63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a541d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.source.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2f9755",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['in_reply_to_status_id'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa68112b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd5c16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3add89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32258594",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_all.rating_numerator.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfcd21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_all.loc[df_all.rating_numerator == 3, 'text'])\n",
    "print(df_all.loc[df_all.rating_numerator == 0, 'text']) \n",
    "print(df_all.loc[df_all.rating_numerator == 1776, 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919a4fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.rating_denominator.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb8bf49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df_all.loc[df_all.rating_denominator == 11, 'text'])\n",
    "print(df_all.loc[df_all.rating_denominator == 50, 'text'])\n",
    "print(df_all.loc[df_all.rating_denominator == 0, 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecddad5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_all['name'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52194586",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all['name'].sort_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff18a6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.loc[df_all['name'] == 'a'].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2368cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d10dd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.p1.sample(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccc70a6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 2. Cleaning the data\n",
    "\n",
    "N.b. Instead of following the prescribed Define-Code-Test framework, I decided (for the sake of simplicity) to move the Test paragraph <u>before</u> the Code paragraph, so that instead of inserting the same line of code after every cleaning operation, all you have to do is scroll back up and run the same line of code, which will output an updated dataset after every subsequent cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d30d761",
   "metadata": {},
   "source": [
    "## 2.1 Define"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758ef0b3",
   "metadata": {},
   "source": [
    "### 2.1.1 Tidiness issues\n",
    "* 3 tables (*df_archive*, *df_images_predictions*, *df_json*) can be combined into 1 table (*df_all*) √\n",
    "    * See \"*Step 0: Gathering the data*\"\n",
    "* Combine the 4 Boolean dog stage columns into 1 object column called ‘*dog_stage*’ √"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e09aa3",
   "metadata": {},
   "source": [
    "### 2.1.2 Quality issues\n",
    "* The following columns can be removed from the dataset due to requirements and/or a lack of necessity to the analysis √:\n",
    "    * '*in_reply_to_status_id*', '*in_reply_to_user_id*',  '*retweeted_status_id*', '*retweeted_status_user_id*’, '*retweeted_status_timestamp*’, ‘*expanded_urls*’, ‘*img_num*’, ‘*p2*’, ‘*p2_conf*’, ‘*p2_dog*’, ‘*p3*’, ‘*p3_conf*’, and ‘*p3_dog*’\n",
    "* The Timestamp column’s datatype is **object** (Panda’s equivalent of string). Additionally, +0000 at the end of the timestamp is a reference to GMT, not the actual time. To maximize efficiency, this should be mentioned in the description of the variable, not in the data itsel √.\n",
    "    * Convert timestamp from object to datetime\n",
    "    * Remove +0000\n",
    "* Part of the requirements is that the dataset should only contain tweets **including photos with original ratings**. Therefor, remove 181 retweets, remove (2356-2075=)281 tweets that contain no photo √.\n",
    "* Replace the values in the ‘*source*’ column with only the name of the source and remove the html formatting for the sake of readability √.\n",
    "* Inconsistent capitalization in image prediction column (p1) √.\n",
    "* *tweet_id* is formatted as an integer, but variables should only be integers when one intends to perform calculations on them √.\n",
    "* Rename various columns with ambigious names √.\n",
    "* Identify and replace all values in the ‘name’ column that are not names: the algorithm selects the word following “*This is…*”. Assuming that the sentence (in this context) will never end after “*is*” and that only names are capitalized, replacing all non-names with “*None*” should solve this problem. Additionally, I decided to replace \"words\" of one character to remove 'a'. By sorting the values of the ‘*name*’ column and concluding that no entry starts with a number or some form of punctuation, this should suffice √."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7899947",
   "metadata": {},
   "source": [
    "#### 2.1.2.1 Additional issues identified after inspecting .csv in Excel\n",
    "* The dog_stage column at the end did not make sense, so I moved it\n",
    "* For some reason some of the confidence intervals had several zeros, which I removed for consistency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38ddbad",
   "metadata": {},
   "source": [
    "### 2.1.3 Order of cleaning operations\n",
    "* Remove replies and retweets\n",
    "* Remove timezone from timestamp and convert from *object* to *datetime*\n",
    "* Drop columns (before inception of *dog_stage* and *shortened_url* to simplify .melt code)\n",
    "* Extracted relevant information from *source* and replaced original values\n",
    "* Inconsistent capitalization p1\n",
    "* *tweet_id* data type\n",
    "* Rename unclear column names\n",
    "* Combine *doggo*, *floofer*, *pupper*, and *puppo* columns into a single column called *dog_stage*\n",
    "* Identify and replace all values in the ‘name’ column that are not names\n",
    "* Changed order of columns (dog_stage column)\n",
    "* Standardized the amount of fraction digits to 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955af134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A copy of the aggregated dataset to perform tests on that can be reiterated an infinite amount of times\n",
    "df_clean = df_all.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc1ad41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# First five rows of aggregated dataset\n",
    "\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d66aa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dimensions of aggregated dataset\n",
    "\n",
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76753efe",
   "metadata": {},
   "source": [
    "## 2.2 Code and Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8114ed01",
   "metadata": {},
   "source": [
    "### 2.2.1 Code (replies and retweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf2f68a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Remove replies\n",
    "df_clean = df_clean[df_clean.in_reply_to_status_id.isnull()]\n",
    "\n",
    "# Remove retweets\n",
    "df_clean = df_clean[df_clean.retweeted_status_id.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53480264",
   "metadata": {},
   "source": [
    "### 2.2.2 Test (replies and retweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6d2387",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensions of aggregated dataset after removal of replies and \n",
    "\n",
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914f5e44",
   "metadata": {},
   "source": [
    "### 2.3.1 Code (timestamp formatting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de958562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove +0000 from timestamp column\n",
    "df_clean.timestamp = df_clean.timestamp.str[:-6]\n",
    "\n",
    "# Convert timestamp from object to datetime data structure\n",
    "df_clean.timestamp = pd.to_datetime(df_clean.timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3b0c90",
   "metadata": {},
   "source": [
    "### 2.3.2 Test (timestamp formatting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c730674",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sample of timestamp column after removal of GMT timezone and updated datatype\n",
    "\n",
    "print(df_clean.timestamp.sample(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af901fff",
   "metadata": {},
   "source": [
    "### 2.3.1 Code (removal of unnecessary columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5c3a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.drop(['in_reply_to_status_id', 'in_reply_to_user_id',  'retweeted_status_id', 'retweeted_status_user_id', 'retweeted_status_timestamp', 'expanded_urls', 'img_num', 'jpg_url', 'p2', 'p2_conf', 'p2_dog', 'p3', 'p3_conf', 'p3_dog'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14da9dd",
   "metadata": {},
   "source": [
    "### 2.3.2 Test (removal of unnecessary columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12edc66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_clean.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399f49c7",
   "metadata": {},
   "source": [
    "### 2.4.1 Code (modification of source column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0b3be9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Output to be used in .replace command in next cell\n",
    "\n",
    "df_clean.source.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe14103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up source column\n",
    "\n",
    "df_clean.source = df_clean.source.replace(\n",
    "    {'<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>':'Twitter for iPhone',\n",
    "    '<a href=\"http://vine.co\" rel=\"nofollow\">Vine - Make a Scene</a>':'Vine',\n",
    "    '<a href=\"http://twitter.com\" rel=\"nofollow\">Twitter Web Client</a>':'Twitter Web Client',\n",
    "    '<a href=\"https://about.twitter.com/products/tweetdeck\" rel=\"nofollow\">TweetDeck</a>':'TweetDeck'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cbfdfe",
   "metadata": {},
   "source": [
    "### 2.4.2 Test (modification of source column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02f3cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.source.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c759d4c",
   "metadata": {},
   "source": [
    "### 2.5.1 Code (standardization of capitalization in p1 column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7bd943",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Inconsistent capitalization p1\n",
    "df_clean.p1 = df_clean.p1.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8efc31c",
   "metadata": {},
   "source": [
    "### 2.5.2 Test (standardization of capitalization in p1 column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7b8527",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.p1.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b61b718",
   "metadata": {},
   "source": [
    "### 2.6.1 Code (data type of tweet_id column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879fd539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dtype tweet_id\n",
    "df_clean['tweet_id'] = df_clean['tweet_id'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4524920",
   "metadata": {},
   "source": [
    "### 2.6.2 Test (data type of tweet_id column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4280fd6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02a35f8",
   "metadata": {},
   "source": [
    "### 2.7.1 Code (removal of tweets without a photo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c3f4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To identify the rows that do not contain a photo\n",
    "\n",
    "df_clean.loc[~df_clean['text'].str.contains ('https', case=False, na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1d8479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove tweets that do not contain a photo by index\n",
    "\n",
    "df_clean.drop([375, 707, 1445], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be277963",
   "metadata": {},
   "source": [
    "### 2.7.2 Test (removal of tweets without a photo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b654394a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To identify the rows that do not contain a photo\n",
    "\n",
    "df_clean.loc[~df_clean['text'].str.contains ('https', case=False, na=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06785f6d",
   "metadata": {},
   "source": [
    "### 2.8.1 Code (column names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929b4390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "\n",
    "df_clean.rename(columns = {'name':'dog_name','p1':'prediction','p1_conf':'CI_prediction','p1_dog':'is_dog'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a25828",
   "metadata": {},
   "source": [
    "### 2.8.2 Test (column names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a5565a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0ab72c",
   "metadata": {},
   "source": [
    "### 2.9.1 Code (aggregation of type of dog columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240352ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add dog_stage, remove additional four columns\n",
    "\n",
    "df_clean = pd.melt(df_clean,\n",
    "                  id_vars = ['tweet_id','timestamp','source','text','rating_numerator','rating_denominator','dog_name','prediction','CI_prediction','is_dog','favorite_count','retweet_count'],\n",
    "                  value_vars = ['doggo','floofer','pupper','puppo'],\n",
    "                  var_name = 'stage',\n",
    "                  value_name = 'dog_stage')\n",
    "\n",
    "# Drop stage column\n",
    "df_clean.drop('stage', axis=1, inplace = True)\n",
    "\n",
    "# Remove duplicates\n",
    "df_clean = df_clean.sort_values('dog_stage').drop_duplicates(subset='tweet_id', keep='last')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd12a14d",
   "metadata": {},
   "source": [
    "### 2.9.2 Test (aggregation of type of dog columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84280abf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Values in dog_stage column\n",
    "\n",
    "df_clean.dog_stage.sort_values().unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9570fd59",
   "metadata": {},
   "source": [
    "### 2.10.1 Code (replacement of non-names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c76dc3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Replace non-names with 'None'\n",
    "\n",
    "df_clean.dog_name = df_clean.dog_name.str.replace('^[a-z]{1,}', 'None')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0d195b",
   "metadata": {},
   "source": [
    "### 2.10.2 Test (replacement of non-names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33dece8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual assessment of effectiveness of RegEx .replace code\n",
    "\n",
    "df_clean.dog_name.sort_values().unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f313d3",
   "metadata": {},
   "source": [
    "### 2.11.1 Code (standardization of fraction digits in CI_prediction column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a9db4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean.round({\"CI_prediction\":6})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ceb0d8b",
   "metadata": {},
   "source": [
    "### 2.11.2 Test (standardization of fraction digits in CI_prediction column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926b83bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_clean.CI_prediction.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20f9c52",
   "metadata": {},
   "source": [
    "### 2.12.1 Code (Rearrangement of columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc9a647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change order of columns (move dog_stage from end to after dog_name)\n",
    "\n",
    "df_clean = df_clean[['tweet_id', 'timestamp', 'source', 'text', 'rating_numerator',\n",
    "       'rating_denominator', 'dog_name', 'dog_stage', 'prediction', 'CI_prediction',\n",
    "       'is_dog', 'favorite_count', 'retweet_count']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa40d91",
   "metadata": {},
   "source": [
    "### 2.12.2 Test (Rearrangement of columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08ed03c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check column order after preceding operation\n",
    "\n",
    "df_clean.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8df5096",
   "metadata": {},
   "source": [
    "### 2.13 Export dataframe to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25448b51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_clean.to_csv('twitter_archive_master.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e22a8f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 3. Analyzing and visualizing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3534a9a4",
   "metadata": {},
   "source": [
    "## 3.1.1 Insight #1\n",
    "What are the 5 most common breeds as identified by the neural network and their absolute frequency?\n",
    "\n",
    "N.b. Only original tweets and based solely on the 1st prediciton.\n",
    "\n",
    "**Conclusion**: The two most popular dog breeds are closely related breeds of the same family: retrievers, a breed known for its natural affection and toleration of children. The subsequent three (pembroke, chihuahua, and pug) are all small dog breeds with fairly high meme potential. By not setting any parameters, it becomes visible that (assuming that the neural network is at least fairly accurate) not all photos actually contain dogs, but it would require manual examination to confirm this hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079b1dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.prediction.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36a3c6b",
   "metadata": {},
   "source": [
    "## 3.1.2 Insight #2\n",
    "\n",
    "What is the relative frequency of (identified) dog stages?\n",
    "\n",
    "**Conclusion**: Although nearly 85% of all dogs are uncategorized, the relative frequency of identified dogs are as following (using Lucid Software's explanation of dog-related lingo in their video \"What is a Pupper? What is a Doggo?\"): The most popular type of floofer (which can be any kind of dog, but usually refers to big dogs with a lot of fur) by a landslide is a smoll doggo, a so-called pupper. A big pupper, commonly known as doggo, is the second most common type of floofer. The intermediate stage between a pupper and a doggo makes up around 1% of all floofers, whereas the authentic fur-heavy floofer makes up less than half a percent of all floofers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0d75a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.dog_stage.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d7aad5",
   "metadata": {},
   "source": [
    "## 3.1.3 Insight #3\n",
    "\n",
    "What are the 10 most popular dog names?\n",
    "\n",
    "**Conclusion**: Aside from the list of the ten most popular dog names, included are some other statistics that reveal some interesting characteristics: there are (2094-704) 1390 registered dog names in this dataset. 930 of those are unique. Considering that only the 10 most popular names already account for 84 observations, the majority of dog names appear only once in this dataset. Additionally, the most frequently used names, Lucy and Charlie, still make up roughly ((22/2094)*100) 1% of all observations, confirming an incredible diversity in dog names!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed20bb35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "name = []\n",
    " \n",
    "count = 0\n",
    " \n",
    "for i in df_clean.dog_name:\n",
    "    if i not in name:\n",
    "        count += 1\n",
    "        name.append(i)\n",
    "        \n",
    "print(\"The number of unique names is:\\n\", count)\n",
    "print(\"\\nThe 10 most popular names are:\\n\",df_clean.dog_name.value_counts()[:10])\n",
    "print(\"\\nThe total amount of entries is:\\n\", df_clean.dog_name.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8292e2",
   "metadata": {},
   "source": [
    "## 3.1.4 Insight #4\n",
    "\n",
    "How is the retweet count distributed?\n",
    "\n",
    "**Conclusion**: As can be derived from the statistics and figure below, this variable is strongly positively skewed and leptokurtic: Nearly 75% of the data falls below the mean, the max is almost 17 standard deviations above the mean, and the IQR is only half a standard deviation. Translated to reality, out of 2079 original tweets, nearly 2,000 got less than 5,000 retweets. A few tweets went viral, leading to a max of nearly 70,000 retweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7bf026",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df_clean.retweet_count)\n",
    "plt.title('Retweet distribution')\n",
    "plt.xlabel('Retweet count')\n",
    "plt.ylabel('Count');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11122402",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.retweet_count.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3737193",
   "metadata": {},
   "source": [
    "## 3.2 Dog stage and tweet virality visualization\n",
    "\n",
    "Is there a correlation between the amount of times a tweet is favorited and retweeted and does this correlation differ between dog stages?\n",
    "\n",
    "**Conclusion**: Juxtaposed with the occurrence of identified dog stages, where pupper was the most frequently occurring, in terms of retweets and favorite count, puppers are outperformed by every other dog stage. Possibly, the owners of the Twitter account WeRateDogs like puppers more than the audience does. Maybe the audience also loves puppers, but do not feel comfortable associating themselves with this type of content. Taking in consideration the dog_stage distribution, perhaps people have grown tired from seeing an overabundance of tweets with photos of puppers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd9e7d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Scatterplot of retweets vs favorite count\n",
    "\n",
    "sns.lmplot(data=df_clean,\n",
    "           x=\"retweet_count\", \n",
    "           y=\"favorite_count\", \n",
    "           height = 6,\n",
    "           aspect=2,\n",
    "           hue=\"dog_stage\",\n",
    "           scatter_kws={'alpha':0.1});\n",
    "\n",
    "plt.title('Favorite vs. retweet count by dog stage');\n",
    "plt.xlabel('Retweet count');\n",
    "plt.ylabel('Favorite count');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f975ad6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
