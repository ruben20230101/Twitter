# A minimalist approach to Data Wrangling
Wrangle and Analyze Data (Udacity)

The project involved working with data from the WeRateDogs twitter account, which rates dogs with humorous commentary. The data consisted of tweets, images, and other information related to the dogs. The data used in this analysis is a combination of a .csv, a .tsv, and a Tweepy-queried database. The data was dirty and needed to be cleaned and wrangled before analysis.

I used Python and its libraries such as Pandas and Numpy to clean and wrangle the data. I applied various techniques such as programmatic and visual analysis, data cleaning, data assessment, and data visualization to understand the data and identify any issues.

One of the challenges I faced during the project was dealing with missing data and inconsistent data types. I had to use different techniques to handle these issues and make the data consistent and clean. After the data was cleaned, I used the visualization libraries Matplotlib and Seaborn to analyze the data and gain insights. I also applied some basic statistical analysis to the data to make some predictions.

The project was a great way to apply the data wrangling skills I had learned in a real-world setting. It also provided an opportunity to work with various data types and formats, which is a common challenge when working with real-world data. I would definitely recommend this project to anyone looking to gain experience working with real-world data and developing their data wrangling skills.

N.b. This repository contains two different Jupyter notebooks: "wrangle_act.ipynb" follows Udacity instructions and is the notebook that the included review is based on. The second notebook, "wrangle_act (original).ipynb" contains my original notebook, which I included because I found Udacity requirements to lead to unnecessary long and repetitive code

I used the DRY principle and was able to reduce the code from ... to ... lines with no loss of functionality.
